{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search 2018 - Tutorial 4: Graph method - Label Propagation\n",
    "## Contents\n",
    "\n",
    "1. [Overview](#head1)\n",
    "  1. [Code Imports](#head11)\n",
    "2. [Iterative Label Propagation](#head2)\n",
    "  1. [Dataset - MNIST Digits](#head21)\n",
    "  2. [Parameters Initialization](#head22)\n",
    "  3. [Algorithm Implementation](#head23)\n",
    "  4. [Evaluation](#head24)\n",
    "  5. [Parameter Tuning](#head25)\n",
    "3. [Iterative Label Propagation over different Search Spaces](#head3)\n",
    "\n",
    "\n",
    "## <a name=\"head1\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that large amounts of data are available in the Web domain, only a small set of such data may be categorized.\n",
    "The goal of this lab is to understand how one can leverage on a reduced set of categorized data, to enrich sets of uncategorized data. \n",
    "\n",
    "Specifically, in this lab you will be using the Label Propagation (LP) algorithm, which consists of a semi-supervised graph approach to annotate uncategorized/unlabelled data starting from a small set of categorized/labelled data.\n",
    "\n",
    "**Lab objectives:**\n",
    "* Implement the iterative version of the Label Propagation algorithm and apply it to the MNIST digits dataset\n",
    "* Evaluate the performance of the Iterative LP algorithm;\n",
    "* Create multiple graphs, one per feature space (visual and textual), and apply the Iterative LP algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head11\"></a> Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head2\"></a> Iterative Label Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a dataset $X=\\{x_1, x_2, \\ldots, x_L, \\ \\ x_{L+1}, \\ldots, x_N\\}$, with $N$ data points, where each $x_i$ consists of some feature representation of document $i$. Given a categories set $C=\\{1, 2, \\ldots, |C|\\}$, it is assumed that the first $L$ data points are labelled with a label $c \\in C$, and the remaining ones are unlabelled.\n",
    "\n",
    "You are asked to implement the Iterative Label Propagation algorithm. Please refer to the \"Mining Data Graphs\" class (lectured on 29/10), namely slides 28, 29 and 30, for a description of the algorithm steps.\n",
    "\n",
    "For more information, you can check the original paper: Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, Bernhard Schoelkopf. Learning with local and global consistency (2004) http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.115.3219\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head21\"></a> Dataset - MNIST Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you implement an algorithm, it is good practice to debug your implementation on a simple dataset. For this purpose, you should first use the MNIST Digits datasets. This dataset is widely used as a baseline to evaluate machine learning algorithms. You can learn more about it in https://en.wikipedia.org/wiki/MNIST_database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST digits images shape: (8, 8)\n",
      "MNIST digits dataset shape: (1797, 64)\n",
      "MNIST digits categories shape: (1797,) - Categories C: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Load mnist digits dataset using sklearn. Every digit image is represented as a 8x8 (64) RGB image.\n",
    "\n",
    "from sklearn import datasets\n",
    "mnist_digits = datasets.load_digits()\n",
    "print(\"MNIST digits images shape: {}\".format(mnist_digits.images[0].shape))\n",
    "print(\"MNIST digits dataset shape: {}\".format(mnist_digits.data.shape))\n",
    "print(\"MNIST digits categories shape: {} - Categories C: {}\".format(mnist_digits.target.shape, set(mnist_digits.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(mnist_digits.data))\n",
    "\n",
    "# Shuffle the array - Modifies the array inplace \n",
    "shuffle(indices)\n",
    "\n",
    "X = mnist_digits.data[indices]\n",
    "y_target = mnist_digits.target[indices]\n",
    "\n",
    "total_images = X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head22\"></a>  Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that 20% of the dataset is labeled\n",
    "labeled_set_size = int(total_images*0.2)\n",
    "\n",
    "# You should tune these values\n",
    "alpha = 1\n",
    "num_iterations = 500\n",
    "sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images labeled: 359 - Total images unlabeled: 1438\n"
     ]
    }
   ],
   "source": [
    "indices_labeled = indices[:labeled_set_size]\n",
    "indices_unlabeled = indices[labeled_set_size:]\n",
    "\n",
    "print(\"Total images labeled: {} - Total images unlabeled: {}\".format(len(indices_labeled), len(indices_unlabeled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to a one-hot-encoded vector\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Keep groundtruth labels\n",
    "Y_true = to_categorical(y_target)\n",
    "\n",
    "Y = to_categorical(y_target)\n",
    "print(Y.shape)\n",
    "\n",
    "# Remove labels of \"unlabeled\" data\n",
    "Y[indices_unlabeled,:] = np.zeros(Y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head23\"></a>  Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (1797, 288)\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Extract features for each image (HoG/CNN/HoC) in X\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "from sklearn.preprocessing import normalize\n",
    "from skimage import color\n",
    "from skimage import data, exposure\n",
    "\n",
    "feature = \"hog\"\n",
    "\n",
    "if feature is \"hog\":\n",
    "    pixels_per_cell=(2,2)\n",
    "    orientations=8\n",
    "    X = []\n",
    "    for img in mnist_digits.images:\n",
    "        hist, hog_img = hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell, visualize=True, block_norm='L2-Hys')\n",
    "        hist = np.squeeze(normalize(hist.reshape(1, -1), norm=\"l2\"))\n",
    "        X.append(hist)\n",
    "    X = np.array(X)\n",
    "    print(\"Shape of feature matrix: {}\".format(X.shape))\n",
    "else:\n",
    "    print(\"No feature selected\")\n",
    "\n",
    "# Step 2 - Initialize matrix F\n",
    "F = Y\n",
    "\n",
    "# Step 3 - Compute matrix W\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "W = np.exp(-1*euclidean_distances(X, X)/(2*sigma**2))\n",
    "\n",
    "# Step 4 - Normalize W\n",
    "D = np.zeros(W.shape)\n",
    "np.fill_diagonal(D, W.sum(axis=0))\n",
    "\n",
    "D12 = np.zeros(D.shape)\n",
    "from numpy.linalg import inv\n",
    "D12 = inv(np.sqrt(D))\n",
    "\n",
    "S = np.dot(D12, W)\n",
    "S = np.dot(S, D12)\n",
    "\n",
    "# Step 5 - Perform the F update step num_iterations steps\n",
    "for i in range(1, num_iterations):\n",
    "    T1 = alpha * S\n",
    "    T1 = np.dot(T1,F)\n",
    "    T2 = 1 * alpha * Y_true\n",
    "    F = T1 + T2\n",
    "F = np.argmax(F, axis=1)\n",
    "Y = to_categorical(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head24\"></a>  Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the results of each run of the Iterative LP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       154\n",
      "          1       1.00      1.00      1.00       142\n",
      "          2       0.00      0.00      0.00       141\n",
      "          3       0.20      1.00      0.34       143\n",
      "          4       1.00      1.00      1.00       150\n",
      "          5       1.00      1.00      1.00       145\n",
      "          6       1.00      1.00      1.00       146\n",
      "          7       0.00      0.00      0.00       135\n",
      "          8       0.00      0.00      0.00       136\n",
      "          9       1.00      1.00      1.00       146\n",
      "\n",
      "avg / total       0.53      0.61      0.54      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscorodrigues/anaconda3/envs/websearch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# The function classification_report computes and prints a set of commonly used metrics.\n",
    "# docs: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "# Get the predictions of the unlabeled documents\n",
    "Y_pred = Y[indices_unlabeled, :]\n",
    "#print(Y_pred)\n",
    "\n",
    "# Get the corresponding groundtruth\n",
    "y_gt = Y_true[indices_unlabeled, :]\n",
    "#print(y_gt)\n",
    "\n",
    "print(classification_report(y_gt, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head25\"></a> Parameter Tuning\n",
    "Assess the impact of each of the algorithm parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head3\"></a> Iterative Label Propagation over different Search Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run your Iterative LP implementation, for each of the previously implemented search spaces (HoG, CNN and HoC).\n",
    "\n",
    "Evaluate and discuss the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
